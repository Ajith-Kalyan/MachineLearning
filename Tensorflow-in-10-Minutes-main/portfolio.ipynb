{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c987fc9-4d4b-425a-a7fe-830289cb1942",
   "metadata": {},
   "source": [
    "# Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516511df-f1a7-4117-a141-0f611d99fef1",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "652bb6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70047a0b-6aaf-425a-8afd-cc3c16daa432",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b1b5d67-e025-4242-a0d2-10a64bbba592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "       Senior Citizen       tenure  Monthly Charges\ncount     7044.000000  7044.000000      7044.000000\nmean         0.162124    32.366695        64.756736\nstd          0.368590    24.560582        30.090786\nmin          0.000000     0.000000        18.250000\n25%          0.000000     9.000000        35.500000\n50%          0.000000    29.000000        70.350000\n75%          0.000000    55.000000        89.850000\nmax          1.000000    72.000000       118.750000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Senior Citizen</th>\n      <th>tenure</th>\n      <th>Monthly Charges</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>7044.000000</td>\n      <td>7044.000000</td>\n      <td>7044.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.162124</td>\n      <td>32.366695</td>\n      <td>64.756736</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.368590</td>\n      <td>24.560582</td>\n      <td>30.090786</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>18.250000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>9.000000</td>\n      <td>35.500000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.000000</td>\n      <td>29.000000</td>\n      <td>70.350000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.000000</td>\n      <td>55.000000</td>\n      <td>89.850000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>72.000000</td>\n      <td>118.750000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be84d87b-2329-4791-a709-475a453d573b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "     Customer ID  Gender  Senior Citizen Partner Dependents  tenure  \\\n0     7590-VHVEA  Female               0     Yes         No       1   \n1     7590-VHVEG  Female               0     Yes         No       1   \n2     5575-GNVDE    Male               0      No         No      34   \n3     3668-QPYBK    Male               0      No         No       2   \n4     7795-CFOCW    Male               0      No         No      45   \n...          ...     ...             ...     ...        ...     ...   \n7039  6840-RESVB    Male               0     Yes        Yes      24   \n7040  2234-XADUH  Female               0     Yes        Yes      72   \n7041  4801-JZAZL  Female               0     Yes        Yes      11   \n7042  8361-LTMKD    Male               1     Yes         No       4   \n7043  3186-AJIEK    Male               0      No         No      66   \n\n     Phone Service    Multiple Lines Internet Service Online Security  ...  \\\n0               No  No phone service              DSL              No  ...   \n1               No  No phone service              DSL              No  ...   \n2              Yes                No              DSL             Yes  ...   \n3              Yes                No              DSL             Yes  ...   \n4               No  No phone service              DSL             Yes  ...   \n...            ...               ...              ...             ...  ...   \n7039           Yes               Yes              DSL             Yes  ...   \n7040           Yes               Yes      Fiber optic              No  ...   \n7041            No  No phone service              DSL             Yes  ...   \n7042           Yes               Yes      Fiber optic              No  ...   \n7043           Yes                No      Fiber optic             Yes  ...   \n\n     Device Protection Tech Support Streaming TV Streaming Movies  \\\n0                   No           No           No               No   \n1                   No           No           No               No   \n2                  Yes           No           No               No   \n3                   No           No           No               No   \n4                  Yes          Yes           No               No   \n...                ...          ...          ...              ...   \n7039               Yes          Yes          Yes              Yes   \n7040               Yes           No          Yes              Yes   \n7041                No           No           No               No   \n7042                No           No           No               No   \n7043               Yes          Yes          Yes              Yes   \n\n            Contract Paperless Billing             Payment Method  \\\n0     Month-to-month               Yes           Electronic check   \n1     Month-to-month               Yes           Electronic check   \n2           One year                No               Mailed check   \n3     Month-to-month               Yes               Mailed check   \n4           One year                No  Bank transfer (automatic)   \n...              ...               ...                        ...   \n7039        One year               Yes               Mailed check   \n7040        One year               Yes    Credit card (automatic)   \n7041  Month-to-month               Yes           Electronic check   \n7042  Month-to-month               Yes               Mailed check   \n7043        Two year               Yes  Bank transfer (automatic)   \n\n     Monthly Charges  Total Charges Churn  \n0              29.85          29.85    No  \n1              29.85          29.85    No  \n2              56.95         1889.5    No  \n3              53.85         108.15   Yes  \n4              42.30        1840.75    No  \n...              ...            ...   ...  \n7039           84.80         1990.5    No  \n7040          103.20         7362.9    No  \n7041           29.60         346.45    No  \n7042           74.40          306.6   Yes  \n7043          105.65         6844.5    No  \n\n[7044 rows x 21 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Customer ID</th>\n      <th>Gender</th>\n      <th>Senior Citizen</th>\n      <th>Partner</th>\n      <th>Dependents</th>\n      <th>tenure</th>\n      <th>Phone Service</th>\n      <th>Multiple Lines</th>\n      <th>Internet Service</th>\n      <th>Online Security</th>\n      <th>...</th>\n      <th>Device Protection</th>\n      <th>Tech Support</th>\n      <th>Streaming TV</th>\n      <th>Streaming Movies</th>\n      <th>Contract</th>\n      <th>Paperless Billing</th>\n      <th>Payment Method</th>\n      <th>Monthly Charges</th>\n      <th>Total Charges</th>\n      <th>Churn</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7590-VHVEA</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>1</td>\n      <td>No</td>\n      <td>No phone service</td>\n      <td>DSL</td>\n      <td>No</td>\n      <td>...</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Month-to-month</td>\n      <td>Yes</td>\n      <td>Electronic check</td>\n      <td>29.85</td>\n      <td>29.85</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7590-VHVEG</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>1</td>\n      <td>No</td>\n      <td>No phone service</td>\n      <td>DSL</td>\n      <td>No</td>\n      <td>...</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Month-to-month</td>\n      <td>Yes</td>\n      <td>Electronic check</td>\n      <td>29.85</td>\n      <td>29.85</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5575-GNVDE</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>No</td>\n      <td>No</td>\n      <td>34</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>DSL</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>One year</td>\n      <td>No</td>\n      <td>Mailed check</td>\n      <td>56.95</td>\n      <td>1889.5</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3668-QPYBK</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>No</td>\n      <td>No</td>\n      <td>2</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>DSL</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Month-to-month</td>\n      <td>Yes</td>\n      <td>Mailed check</td>\n      <td>53.85</td>\n      <td>108.15</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7795-CFOCW</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>No</td>\n      <td>No</td>\n      <td>45</td>\n      <td>No</td>\n      <td>No phone service</td>\n      <td>DSL</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>One year</td>\n      <td>No</td>\n      <td>Bank transfer (automatic)</td>\n      <td>42.30</td>\n      <td>1840.75</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7039</th>\n      <td>6840-RESVB</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>24</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>DSL</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>One year</td>\n      <td>Yes</td>\n      <td>Mailed check</td>\n      <td>84.80</td>\n      <td>1990.5</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>7040</th>\n      <td>2234-XADUH</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>72</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Fiber optic</td>\n      <td>No</td>\n      <td>...</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>One year</td>\n      <td>Yes</td>\n      <td>Credit card (automatic)</td>\n      <td>103.20</td>\n      <td>7362.9</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>7041</th>\n      <td>4801-JZAZL</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>11</td>\n      <td>No</td>\n      <td>No phone service</td>\n      <td>DSL</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Month-to-month</td>\n      <td>Yes</td>\n      <td>Electronic check</td>\n      <td>29.60</td>\n      <td>346.45</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>7042</th>\n      <td>8361-LTMKD</td>\n      <td>Male</td>\n      <td>1</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>4</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Fiber optic</td>\n      <td>No</td>\n      <td>...</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Month-to-month</td>\n      <td>Yes</td>\n      <td>Mailed check</td>\n      <td>74.40</td>\n      <td>306.6</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>7043</th>\n      <td>3186-AJIEK</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>No</td>\n      <td>No</td>\n      <td>66</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Fiber optic</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Two year</td>\n      <td>Yes</td>\n      <td>Bank transfer (automatic)</td>\n      <td>105.65</td>\n      <td>6844.5</td>\n      <td>No</td>\n    </tr>\n  </tbody>\n</table>\n<p>7044 rows × 21 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2148170b-8872-4d50-b0ef-292fc54518a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "      Senior Citizen  tenure  Monthly Charges  Gender_Female  Gender_Male  \\\n0                  0       1            29.85              1            0   \n1                  0       1            29.85              1            0   \n2                  0      34            56.95              0            1   \n3                  0       2            53.85              0            1   \n4                  0      45            42.30              0            1   \n...              ...     ...              ...            ...          ...   \n7039               0      24            84.80              0            1   \n7040               0      72           103.20              1            0   \n7041               0      11            29.60              1            0   \n7042               1       4            74.40              0            1   \n7043               0      66           105.65              0            1   \n\n      Partner_No  Partner_Yes  Dependents_No  Dependents_Yes  \\\n0              0            1              1               0   \n1              0            1              1               0   \n2              1            0              1               0   \n3              1            0              1               0   \n4              1            0              1               0   \n...          ...          ...            ...             ...   \n7039           0            1              0               1   \n7040           0            1              0               1   \n7041           0            1              0               1   \n7042           0            1              1               0   \n7043           1            0              1               0   \n\n      Phone Service_No  ...  Total Charges_995.35  Total Charges_996.45  \\\n0                    1  ...                     0                     0   \n1                    1  ...                     0                     0   \n2                    0  ...                     0                     0   \n3                    0  ...                     0                     0   \n4                    1  ...                     0                     0   \n...                ...  ...                   ...                   ...   \n7039                 0  ...                     0                     0   \n7040                 0  ...                     0                     0   \n7041                 1  ...                     0                     0   \n7042                 0  ...                     0                     0   \n7043                 0  ...                     0                     0   \n\n      Total Charges_996.85  Total Charges_996.95  Total Charges_997.65  \\\n0                        0                     0                     0   \n1                        0                     0                     0   \n2                        0                     0                     0   \n3                        0                     0                     0   \n4                        0                     0                     0   \n...                    ...                   ...                   ...   \n7039                     0                     0                     0   \n7040                     0                     0                     0   \n7041                     0                     0                     0   \n7042                     0                     0                     0   \n7043                     0                     0                     0   \n\n      Total Charges_997.75  Total Charges_998.1  Total Charges_999.45  \\\n0                        0                    0                     0   \n1                        0                    0                     0   \n2                        0                    0                     0   \n3                        0                    0                     0   \n4                        0                    0                     0   \n...                    ...                  ...                   ...   \n7039                     0                    0                     0   \n7040                     0                    0                     0   \n7041                     0                    0                     0   \n7042                     0                    0                     0   \n7043                     0                    0                     0   \n\n      Total Charges_999.8  Total Charges_999.9  \n0                       0                    0  \n1                       0                    0  \n2                       0                    0  \n3                       0                    0  \n4                       0                    0  \n...                   ...                  ...  \n7039                    0                    0  \n7040                    0                    0  \n7041                    0                    0  \n7042                    0                    0  \n7043                    0                    0  \n\n[7044 rows x 6575 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Senior Citizen</th>\n      <th>tenure</th>\n      <th>Monthly Charges</th>\n      <th>Gender_Female</th>\n      <th>Gender_Male</th>\n      <th>Partner_No</th>\n      <th>Partner_Yes</th>\n      <th>Dependents_No</th>\n      <th>Dependents_Yes</th>\n      <th>Phone Service_No</th>\n      <th>...</th>\n      <th>Total Charges_995.35</th>\n      <th>Total Charges_996.45</th>\n      <th>Total Charges_996.85</th>\n      <th>Total Charges_996.95</th>\n      <th>Total Charges_997.65</th>\n      <th>Total Charges_997.75</th>\n      <th>Total Charges_998.1</th>\n      <th>Total Charges_999.45</th>\n      <th>Total Charges_999.8</th>\n      <th>Total Charges_999.9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>29.85</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1</td>\n      <td>29.85</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>34</td>\n      <td>56.95</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>2</td>\n      <td>53.85</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>45</td>\n      <td>42.30</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7039</th>\n      <td>0</td>\n      <td>24</td>\n      <td>84.80</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7040</th>\n      <td>0</td>\n      <td>72</td>\n      <td>103.20</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7041</th>\n      <td>0</td>\n      <td>11</td>\n      <td>29.60</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7042</th>\n      <td>1</td>\n      <td>4</td>\n      <td>74.40</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7043</th>\n      <td>0</td>\n      <td>66</td>\n      <td>105.65</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>7044 rows × 6575 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.get_dummies(df.drop(['Churn', 'Customer ID'], axis=1))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01a81701-0690-4521-a62a-cb45c2482821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0       0\n1       0\n2       0\n3       1\n4       0\n       ..\n7039    0\n7040    0\n7041    0\n7042    1\n7043    0\nName: Churn, Length: 7044, dtype: int64"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['Churn'].apply(lambda x: 1 if x==\"Yes\" else 0)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cff0a310-49c5-483b-83b4-2783e203863f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dec307e8-c87b-4f42-9301-1fe85dab94c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "      Senior Citizen  tenure  Monthly Charges  Gender_Female  Gender_Male  \\\n6074               0      64            24.90              1            0   \n3497               0      25            74.30              0            1   \n3442               0      34            60.80              1            0   \n549                1      50           101.90              0            1   \n5104               0      28            82.85              1            0   \n...              ...     ...              ...            ...          ...   \n3558               1      33            59.45              1            0   \n6910               0       1            53.55              1            0   \n1891               0       1            21.00              1            0   \n183                0       8            84.50              0            1   \n2847               0       2            62.15              1            0   \n\n      Partner_No  Partner_Yes  Dependents_No  Dependents_Yes  \\\n6074           0            1              0               1   \n3497           1            0              1               0   \n3442           0            1              0               1   \n549            0            1              1               0   \n5104           0            1              0               1   \n...          ...          ...            ...             ...   \n3558           1            0              1               0   \n6910           0            1              1               0   \n1891           0            1              0               1   \n183            1            0              1               0   \n2847           0            1              1               0   \n\n      Phone Service_No  ...  Total Charges_995.35  Total Charges_996.45  \\\n6074                 0  ...                     0                     0   \n3497                 0  ...                     0                     0   \n3442                 0  ...                     0                     0   \n549                  0  ...                     0                     0   \n5104                 0  ...                     0                     0   \n...                ...  ...                   ...                   ...   \n3558                 1  ...                     0                     0   \n6910                 0  ...                     0                     0   \n1891                 0  ...                     0                     0   \n183                  0  ...                     0                     0   \n2847                 0  ...                     0                     0   \n\n      Total Charges_996.85  Total Charges_996.95  Total Charges_997.65  \\\n6074                     0                     0                     0   \n3497                     0                     0                     0   \n3442                     0                     0                     0   \n549                      0                     0                     0   \n5104                     0                     0                     0   \n...                    ...                   ...                   ...   \n3558                     0                     0                     0   \n6910                     0                     0                     0   \n1891                     0                     0                     0   \n183                      0                     0                     0   \n2847                     0                     0                     0   \n\n      Total Charges_997.75  Total Charges_998.1  Total Charges_999.45  \\\n6074                     0                    0                     0   \n3497                     0                    0                     0   \n3442                     0                    0                     0   \n549                      0                    0                     0   \n5104                     0                    0                     0   \n...                    ...                  ...                   ...   \n3558                     0                    0                     0   \n6910                     0                    0                     0   \n1891                     0                    0                     0   \n183                      0                    0                     0   \n2847                     0                    0                     0   \n\n      Total Charges_999.8  Total Charges_999.9  \n6074                    0                    0  \n3497                    0                    0  \n3442                    0                    0  \n549                     0                    0  \n5104                    0                    0  \n...                   ...                  ...  \n3558                    0                    0  \n6910                    0                    0  \n1891                    0                    0  \n183                     0                    0  \n2847                    0                    0  \n\n[5635 rows x 6575 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Senior Citizen</th>\n      <th>tenure</th>\n      <th>Monthly Charges</th>\n      <th>Gender_Female</th>\n      <th>Gender_Male</th>\n      <th>Partner_No</th>\n      <th>Partner_Yes</th>\n      <th>Dependents_No</th>\n      <th>Dependents_Yes</th>\n      <th>Phone Service_No</th>\n      <th>...</th>\n      <th>Total Charges_995.35</th>\n      <th>Total Charges_996.45</th>\n      <th>Total Charges_996.85</th>\n      <th>Total Charges_996.95</th>\n      <th>Total Charges_997.65</th>\n      <th>Total Charges_997.75</th>\n      <th>Total Charges_998.1</th>\n      <th>Total Charges_999.45</th>\n      <th>Total Charges_999.8</th>\n      <th>Total Charges_999.9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6074</th>\n      <td>0</td>\n      <td>64</td>\n      <td>24.90</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3497</th>\n      <td>0</td>\n      <td>25</td>\n      <td>74.30</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3442</th>\n      <td>0</td>\n      <td>34</td>\n      <td>60.80</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>549</th>\n      <td>1</td>\n      <td>50</td>\n      <td>101.90</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5104</th>\n      <td>0</td>\n      <td>28</td>\n      <td>82.85</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3558</th>\n      <td>1</td>\n      <td>33</td>\n      <td>59.45</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6910</th>\n      <td>0</td>\n      <td>1</td>\n      <td>53.55</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1891</th>\n      <td>0</td>\n      <td>1</td>\n      <td>21.00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>183</th>\n      <td>0</td>\n      <td>8</td>\n      <td>84.50</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2847</th>\n      <td>0</td>\n      <td>2</td>\n      <td>62.15</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5635 rows × 6575 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42583d64-4cd4-4d29-8ad6-fc0952ed5c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "6074    0\n3497    0\n3442    0\n549     0\n5104    0\nName: Churn, dtype: int64"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a95e18-f94c-42b0-b4ae-513af9759019",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a4119fd-6f3d-4cc7-9a34-8f050d57c7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f569ee-9a7e-4aba-aada-51f1d8dc7364",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aeb682c9-d2f6-473a-a2d3-f3f5d5d37b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use sequential to build model by adding dense layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a22b218-0eb7-48dd-85e9-b8f6266f85cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=32, activation='relu', input_dim=len(X_train.columns)))\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffba2c12-29f8-44d6-8e82-467383d25d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47a90a9-f0bb-4bc6-87bd-577ac78d6330",
   "metadata": {},
   "source": [
    "## Fit and predict model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b5011df-55fa-43e8-ae90-a32b1c1bbc8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "89/89 [==============================] - 2s 10ms/step - loss: 0.5118 - accuracy: 0.7594\n",
      "Epoch 2/500\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.4905 - accuracy: 0.7697\n",
      "Epoch 3/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4888 - accuracy: 0.7723\n",
      "Epoch 4/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4857 - accuracy: 0.7713\n",
      "Epoch 5/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4831 - accuracy: 0.7714\n",
      "Epoch 6/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4796 - accuracy: 0.7734\n",
      "Epoch 7/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4832 - accuracy: 0.7718\n",
      "Epoch 8/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4771 - accuracy: 0.7778\n",
      "Epoch 9/500\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 0.4749 - accuracy: 0.7762\n",
      "Epoch 10/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4733 - accuracy: 0.7778\n",
      "Epoch 11/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4705 - accuracy: 0.7769\n",
      "Epoch 12/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4747 - accuracy: 0.7695\n",
      "Epoch 13/500\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 0.4698 - accuracy: 0.7792\n",
      "Epoch 14/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4717 - accuracy: 0.7768\n",
      "Epoch 15/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4653 - accuracy: 0.7783\n",
      "Epoch 16/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4670 - accuracy: 0.7791\n",
      "Epoch 17/500\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 0.4602 - accuracy: 0.7773\n",
      "Epoch 18/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4617 - accuracy: 0.7815\n",
      "Epoch 19/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4633 - accuracy: 0.7799\n",
      "Epoch 20/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4585 - accuracy: 0.7819\n",
      "Epoch 21/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4589 - accuracy: 0.7854\n",
      "Epoch 22/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4582 - accuracy: 0.7828\n",
      "Epoch 23/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4732 - accuracy: 0.7750\n",
      "Epoch 24/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4636 - accuracy: 0.7787\n",
      "Epoch 25/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4616 - accuracy: 0.7785\n",
      "Epoch 26/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4578 - accuracy: 0.7794\n",
      "Epoch 27/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4579 - accuracy: 0.7789\n",
      "Epoch 28/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4598 - accuracy: 0.7807\n",
      "Epoch 29/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4567 - accuracy: 0.7860\n",
      "Epoch 30/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4551 - accuracy: 0.7823\n",
      "Epoch 31/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4559 - accuracy: 0.7849\n",
      "Epoch 32/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4547 - accuracy: 0.7869\n",
      "Epoch 33/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4558 - accuracy: 0.7824\n",
      "Epoch 34/500\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 0.4603 - accuracy: 0.7780\n",
      "Epoch 35/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4632 - accuracy: 0.7755\n",
      "Epoch 36/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4589 - accuracy: 0.7755\n",
      "Epoch 37/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4670 - accuracy: 0.7792\n",
      "Epoch 38/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4573 - accuracy: 0.7817\n",
      "Epoch 39/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4588 - accuracy: 0.7823\n",
      "Epoch 40/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4558 - accuracy: 0.7824\n",
      "Epoch 41/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4532 - accuracy: 0.7849\n",
      "Epoch 42/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4551 - accuracy: 0.7839\n",
      "Epoch 43/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4518 - accuracy: 0.7839\n",
      "Epoch 44/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4499 - accuracy: 0.7863\n",
      "Epoch 45/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4521 - accuracy: 0.7846\n",
      "Epoch 46/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4546 - accuracy: 0.7826\n",
      "Epoch 47/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4498 - accuracy: 0.7881\n",
      "Epoch 48/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4524 - accuracy: 0.7842\n",
      "Epoch 49/500\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 0.4502 - accuracy: 0.7833\n",
      "Epoch 50/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4520 - accuracy: 0.7851\n",
      "Epoch 51/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4508 - accuracy: 0.7870\n",
      "Epoch 52/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4494 - accuracy: 0.7869\n",
      "Epoch 53/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4515 - accuracy: 0.7849\n",
      "Epoch 54/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4532 - accuracy: 0.7846\n",
      "Epoch 55/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4534 - accuracy: 0.7849\n",
      "Epoch 56/500\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 0.4508 - accuracy: 0.7808\n",
      "Epoch 57/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4467 - accuracy: 0.7913\n",
      "Epoch 58/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4488 - accuracy: 0.7894\n",
      "Epoch 59/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4462 - accuracy: 0.7915\n",
      "Epoch 60/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4505 - accuracy: 0.7865\n",
      "Epoch 61/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4447 - accuracy: 0.7872\n",
      "Epoch 62/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4489 - accuracy: 0.7819\n",
      "Epoch 63/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4513 - accuracy: 0.7854\n",
      "Epoch 64/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4477 - accuracy: 0.7830\n",
      "Epoch 65/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4497 - accuracy: 0.7863\n",
      "Epoch 66/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4455 - accuracy: 0.7888\n",
      "Epoch 67/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4443 - accuracy: 0.7881\n",
      "Epoch 68/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4471 - accuracy: 0.7883\n",
      "Epoch 69/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4447 - accuracy: 0.7913\n",
      "Epoch 70/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4452 - accuracy: 0.7870\n",
      "Epoch 71/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4465 - accuracy: 0.7858\n",
      "Epoch 72/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4458 - accuracy: 0.7858\n",
      "Epoch 73/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4425 - accuracy: 0.7890\n",
      "Epoch 74/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4531 - accuracy: 0.7835\n",
      "Epoch 75/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4442 - accuracy: 0.7872\n",
      "Epoch 76/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4490 - accuracy: 0.7885\n",
      "Epoch 77/500\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 0.4540 - accuracy: 0.7847\n",
      "Epoch 78/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4425 - accuracy: 0.7890\n",
      "Epoch 79/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4465 - accuracy: 0.7849\n",
      "Epoch 80/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4483 - accuracy: 0.7854\n",
      "Epoch 81/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4487 - accuracy: 0.7904\n",
      "Epoch 82/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4396 - accuracy: 0.7908\n",
      "Epoch 83/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4452 - accuracy: 0.7854\n",
      "Epoch 84/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4418 - accuracy: 0.7892\n",
      "Epoch 85/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4527 - accuracy: 0.7854\n",
      "Epoch 86/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4429 - accuracy: 0.7881\n",
      "Epoch 87/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4425 - accuracy: 0.7840\n",
      "Epoch 88/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4411 - accuracy: 0.7888\n",
      "Epoch 89/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4433 - accuracy: 0.7892\n",
      "Epoch 90/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4452 - accuracy: 0.7881\n",
      "Epoch 91/500\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 0.4423 - accuracy: 0.7874\n",
      "Epoch 92/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4413 - accuracy: 0.7863\n",
      "Epoch 93/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4410 - accuracy: 0.7913\n",
      "Epoch 94/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4355 - accuracy: 0.7943\n",
      "Epoch 95/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4373 - accuracy: 0.7909\n",
      "Epoch 96/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4394 - accuracy: 0.7911\n",
      "Epoch 97/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4417 - accuracy: 0.7888\n",
      "Epoch 98/500\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 0.4550 - accuracy: 0.7846\n",
      "Epoch 99/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4430 - accuracy: 0.7899\n",
      "Epoch 100/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4403 - accuracy: 0.7869\n",
      "Epoch 101/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4407 - accuracy: 0.7922\n",
      "Epoch 102/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4450 - accuracy: 0.7883\n",
      "Epoch 103/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4380 - accuracy: 0.7920\n",
      "Epoch 104/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4383 - accuracy: 0.7913\n",
      "Epoch 105/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4379 - accuracy: 0.7881\n",
      "Epoch 106/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4439 - accuracy: 0.7892\n",
      "Epoch 107/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4394 - accuracy: 0.7860\n",
      "Epoch 108/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4447 - accuracy: 0.7906\n",
      "Epoch 109/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4375 - accuracy: 0.7920\n",
      "Epoch 110/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4370 - accuracy: 0.7888\n",
      "Epoch 111/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4383 - accuracy: 0.7922\n",
      "Epoch 112/500\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 0.4400 - accuracy: 0.7881\n",
      "Epoch 113/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4370 - accuracy: 0.7911\n",
      "Epoch 114/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4350 - accuracy: 0.7902\n",
      "Epoch 115/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4348 - accuracy: 0.7924\n",
      "Epoch 116/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4383 - accuracy: 0.7876\n",
      "Epoch 117/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4353 - accuracy: 0.7940\n",
      "Epoch 118/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4381 - accuracy: 0.7901\n",
      "Epoch 119/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4384 - accuracy: 0.7865\n",
      "Epoch 120/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4358 - accuracy: 0.7888\n",
      "Epoch 121/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4354 - accuracy: 0.7918\n",
      "Epoch 122/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4386 - accuracy: 0.7911\n",
      "Epoch 123/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4362 - accuracy: 0.7947\n",
      "Epoch 124/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4419 - accuracy: 0.7886\n",
      "Epoch 125/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4375 - accuracy: 0.7922\n",
      "Epoch 126/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4347 - accuracy: 0.7913\n",
      "Epoch 127/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4382 - accuracy: 0.7952\n",
      "Epoch 128/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4332 - accuracy: 0.7915\n",
      "Epoch 129/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4375 - accuracy: 0.7881\n",
      "Epoch 130/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4323 - accuracy: 0.7922\n",
      "Epoch 131/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4361 - accuracy: 0.7917\n",
      "Epoch 132/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4353 - accuracy: 0.7938\n",
      "Epoch 133/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4415 - accuracy: 0.7888\n",
      "Epoch 134/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4346 - accuracy: 0.7929\n",
      "Epoch 135/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4409 - accuracy: 0.7899\n",
      "Epoch 136/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4356 - accuracy: 0.7894\n",
      "Epoch 137/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4340 - accuracy: 0.7922\n",
      "Epoch 138/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4342 - accuracy: 0.7938\n",
      "Epoch 139/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4306 - accuracy: 0.7934\n",
      "Epoch 140/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4354 - accuracy: 0.7885\n",
      "Epoch 141/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4336 - accuracy: 0.7934\n",
      "Epoch 142/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4322 - accuracy: 0.7940\n",
      "Epoch 143/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4378 - accuracy: 0.7899\n",
      "Epoch 144/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4446 - accuracy: 0.7911\n",
      "Epoch 145/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4351 - accuracy: 0.7980\n",
      "Epoch 146/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4361 - accuracy: 0.7929\n",
      "Epoch 147/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4317 - accuracy: 0.7931\n",
      "Epoch 148/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4316 - accuracy: 0.7952\n",
      "Epoch 149/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4302 - accuracy: 0.7982\n",
      "Epoch 150/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4336 - accuracy: 0.7929\n",
      "Epoch 151/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4316 - accuracy: 0.7947\n",
      "Epoch 152/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4334 - accuracy: 0.7936\n",
      "Epoch 153/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4337 - accuracy: 0.7924\n",
      "Epoch 154/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4330 - accuracy: 0.7936\n",
      "Epoch 155/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4327 - accuracy: 0.7943\n",
      "Epoch 156/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4352 - accuracy: 0.7925\n",
      "Epoch 157/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4497 - accuracy: 0.7858\n",
      "Epoch 158/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4358 - accuracy: 0.7925\n",
      "Epoch 159/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4326 - accuracy: 0.7931\n",
      "Epoch 160/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4362 - accuracy: 0.7870\n",
      "Epoch 161/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4422 - accuracy: 0.7902\n",
      "Epoch 162/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4373 - accuracy: 0.7901\n",
      "Epoch 163/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4346 - accuracy: 0.7886\n",
      "Epoch 164/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4306 - accuracy: 0.7972\n",
      "Epoch 165/500\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 0.4316 - accuracy: 0.7941\n",
      "Epoch 166/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4406 - accuracy: 0.7885\n",
      "Epoch 167/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4308 - accuracy: 0.7929\n",
      "Epoch 168/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4325 - accuracy: 0.7936\n",
      "Epoch 169/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4309 - accuracy: 0.7929\n",
      "Epoch 170/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4340 - accuracy: 0.7943\n",
      "Epoch 171/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4311 - accuracy: 0.7943\n",
      "Epoch 172/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4321 - accuracy: 0.7906\n",
      "Epoch 173/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4348 - accuracy: 0.7913\n",
      "Epoch 174/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4330 - accuracy: 0.7924\n",
      "Epoch 175/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4340 - accuracy: 0.7936\n",
      "Epoch 176/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4278 - accuracy: 0.7934\n",
      "Epoch 177/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4322 - accuracy: 0.7961\n",
      "Epoch 178/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4298 - accuracy: 0.7973\n",
      "Epoch 179/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4357 - accuracy: 0.7956\n",
      "Epoch 180/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4333 - accuracy: 0.7933\n",
      "Epoch 181/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4310 - accuracy: 0.7925\n",
      "Epoch 182/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4297 - accuracy: 0.7940\n",
      "Epoch 183/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4317 - accuracy: 0.7961\n",
      "Epoch 184/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4318 - accuracy: 0.7925\n",
      "Epoch 185/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4329 - accuracy: 0.7911\n",
      "Epoch 186/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4316 - accuracy: 0.7968\n",
      "Epoch 187/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4319 - accuracy: 0.7920\n",
      "Epoch 188/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4302 - accuracy: 0.7956\n",
      "Epoch 189/500\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 0.4345 - accuracy: 0.7929\n",
      "Epoch 190/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4260 - accuracy: 0.7945\n",
      "Epoch 191/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4303 - accuracy: 0.7952\n",
      "Epoch 192/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4296 - accuracy: 0.7936\n",
      "Epoch 193/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4323 - accuracy: 0.7959\n",
      "Epoch 194/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4277 - accuracy: 0.7950\n",
      "Epoch 195/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4269 - accuracy: 0.7925\n",
      "Epoch 196/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4307 - accuracy: 0.7963\n",
      "Epoch 197/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4316 - accuracy: 0.7961\n",
      "Epoch 198/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4266 - accuracy: 0.7968\n",
      "Epoch 199/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4333 - accuracy: 0.7943\n",
      "Epoch 200/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4328 - accuracy: 0.7954\n",
      "Epoch 201/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4255 - accuracy: 0.8000\n",
      "Epoch 202/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4277 - accuracy: 0.7945\n",
      "Epoch 203/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4312 - accuracy: 0.7940\n",
      "Epoch 204/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4252 - accuracy: 0.7988\n",
      "Epoch 205/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4272 - accuracy: 0.7963\n",
      "Epoch 206/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4256 - accuracy: 0.7963\n",
      "Epoch 207/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4252 - accuracy: 0.8000\n",
      "Epoch 208/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4277 - accuracy: 0.7972\n",
      "Epoch 209/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4303 - accuracy: 0.7952\n",
      "Epoch 210/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4299 - accuracy: 0.7922\n",
      "Epoch 211/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4299 - accuracy: 0.7945\n",
      "Epoch 212/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4301 - accuracy: 0.7929\n",
      "Epoch 213/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4296 - accuracy: 0.7925\n",
      "Epoch 214/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4284 - accuracy: 0.7963\n",
      "Epoch 215/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4295 - accuracy: 0.7996\n",
      "Epoch 216/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4286 - accuracy: 0.7970\n",
      "Epoch 217/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4301 - accuracy: 0.7938\n",
      "Epoch 218/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4268 - accuracy: 0.7998\n",
      "Epoch 219/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4307 - accuracy: 0.7925\n",
      "Epoch 220/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4320 - accuracy: 0.7917\n",
      "Epoch 221/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4360 - accuracy: 0.7917\n",
      "Epoch 222/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4259 - accuracy: 0.7988\n",
      "Epoch 223/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4287 - accuracy: 0.7924\n",
      "Epoch 224/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4312 - accuracy: 0.7959\n",
      "Epoch 225/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4247 - accuracy: 0.8004\n",
      "Epoch 226/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4270 - accuracy: 0.7940\n",
      "Epoch 227/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4313 - accuracy: 0.7911\n",
      "Epoch 228/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4349 - accuracy: 0.7945\n",
      "Epoch 229/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4287 - accuracy: 0.7993\n",
      "Epoch 230/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4261 - accuracy: 0.7945\n",
      "Epoch 231/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4265 - accuracy: 0.7956\n",
      "Epoch 232/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4255 - accuracy: 0.7986\n",
      "Epoch 233/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4214 - accuracy: 0.7954\n",
      "Epoch 234/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4236 - accuracy: 0.8043\n",
      "Epoch 235/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4250 - accuracy: 0.8007\n",
      "Epoch 236/500\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 0.4270 - accuracy: 0.7973\n",
      "Epoch 237/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4369 - accuracy: 0.7931\n",
      "Epoch 238/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4246 - accuracy: 0.7979\n",
      "Epoch 239/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4259 - accuracy: 0.7977\n",
      "Epoch 240/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4233 - accuracy: 0.8005\n",
      "Epoch 241/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4305 - accuracy: 0.7984\n",
      "Epoch 242/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4252 - accuracy: 0.7970\n",
      "Epoch 243/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4323 - accuracy: 0.7920\n",
      "Epoch 244/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4269 - accuracy: 0.7940\n",
      "Epoch 245/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4270 - accuracy: 0.7950\n",
      "Epoch 246/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4291 - accuracy: 0.7957\n",
      "Epoch 247/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4220 - accuracy: 0.8027\n",
      "Epoch 248/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4254 - accuracy: 0.7980\n",
      "Epoch 249/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4251 - accuracy: 0.7956\n",
      "Epoch 250/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4349 - accuracy: 0.7888\n",
      "Epoch 251/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4281 - accuracy: 0.7929\n",
      "Epoch 252/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4228 - accuracy: 0.8021\n",
      "Epoch 253/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4257 - accuracy: 0.7952\n",
      "Epoch 254/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4234 - accuracy: 0.7998\n",
      "Epoch 255/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4248 - accuracy: 0.7998\n",
      "Epoch 256/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4240 - accuracy: 0.7968\n",
      "Epoch 257/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4201 - accuracy: 0.8051\n",
      "Epoch 258/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4249 - accuracy: 0.7988\n",
      "Epoch 259/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4322 - accuracy: 0.7881\n",
      "Epoch 260/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4257 - accuracy: 0.7972\n",
      "Epoch 261/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4270 - accuracy: 0.7968\n",
      "Epoch 262/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4255 - accuracy: 0.8000\n",
      "Epoch 263/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4243 - accuracy: 0.8009\n",
      "Epoch 264/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4233 - accuracy: 0.8002\n",
      "Epoch 265/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4249 - accuracy: 0.7977\n",
      "Epoch 266/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4209 - accuracy: 0.7959\n",
      "Epoch 267/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4271 - accuracy: 0.7984\n",
      "Epoch 268/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4241 - accuracy: 0.7977\n",
      "Epoch 269/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4242 - accuracy: 0.7975\n",
      "Epoch 270/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4242 - accuracy: 0.7982\n",
      "Epoch 271/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4259 - accuracy: 0.7945\n",
      "Epoch 272/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4209 - accuracy: 0.7998\n",
      "Epoch 273/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4287 - accuracy: 0.7986\n",
      "Epoch 274/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4234 - accuracy: 0.8014\n",
      "Epoch 275/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4261 - accuracy: 0.7968\n",
      "Epoch 276/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4220 - accuracy: 0.7989\n",
      "Epoch 277/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4195 - accuracy: 0.7979\n",
      "Epoch 278/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4216 - accuracy: 0.8014\n",
      "Epoch 279/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.4220 - accuracy: 0.7970\n",
      "Epoch 280/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.4289 - accuracy: 0.7956\n",
      "Epoch 281/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.4314 - accuracy: 0.7973\n",
      "Epoch 282/500\n",
      "89/89 [==============================] - 0s 6ms/step - loss: 0.4249 - accuracy: 0.7973\n",
      "Epoch 283/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4219 - accuracy: 0.7979\n",
      "Epoch 284/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4235 - accuracy: 0.8009\n",
      "Epoch 285/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4240 - accuracy: 0.7989\n",
      "Epoch 286/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4230 - accuracy: 0.7991\n",
      "Epoch 287/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4239 - accuracy: 0.7961\n",
      "Epoch 288/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4238 - accuracy: 0.7972\n",
      "Epoch 289/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4247 - accuracy: 0.8009\n",
      "Epoch 290/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4221 - accuracy: 0.7968\n",
      "Epoch 291/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4195 - accuracy: 0.8050\n",
      "Epoch 292/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4207 - accuracy: 0.7993\n",
      "Epoch 293/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4219 - accuracy: 0.7986\n",
      "Epoch 294/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4238 - accuracy: 0.7995\n",
      "Epoch 295/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4384 - accuracy: 0.7858\n",
      "Epoch 296/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4308 - accuracy: 0.7947\n",
      "Epoch 297/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4221 - accuracy: 0.8030\n",
      "Epoch 298/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4266 - accuracy: 0.7984\n",
      "Epoch 299/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4242 - accuracy: 0.7998\n",
      "Epoch 300/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4244 - accuracy: 0.8007\n",
      "Epoch 301/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4223 - accuracy: 0.7991\n",
      "Epoch 302/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4237 - accuracy: 0.7952\n",
      "Epoch 303/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4239 - accuracy: 0.8011\n",
      "Epoch 304/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4233 - accuracy: 0.7982\n",
      "Epoch 305/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4225 - accuracy: 0.8009\n",
      "Epoch 306/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4212 - accuracy: 0.8005\n",
      "Epoch 307/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4236 - accuracy: 0.7991\n",
      "Epoch 308/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4465 - accuracy: 0.7918\n",
      "Epoch 309/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4262 - accuracy: 0.7996\n",
      "Epoch 310/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4229 - accuracy: 0.8005\n",
      "Epoch 311/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4272 - accuracy: 0.7973\n",
      "Epoch 312/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4221 - accuracy: 0.8007\n",
      "Epoch 313/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4216 - accuracy: 0.7965\n",
      "Epoch 314/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4323 - accuracy: 0.7952\n",
      "Epoch 315/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4228 - accuracy: 0.7968\n",
      "Epoch 316/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4200 - accuracy: 0.8027\n",
      "Epoch 317/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4223 - accuracy: 0.8002\n",
      "Epoch 318/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8035\n",
      "Epoch 319/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4202 - accuracy: 0.8004\n",
      "Epoch 320/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4215 - accuracy: 0.8012\n",
      "Epoch 321/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4211 - accuracy: 0.7980\n",
      "Epoch 322/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4200 - accuracy: 0.8028\n",
      "Epoch 323/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4273 - accuracy: 0.7950\n",
      "Epoch 324/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4225 - accuracy: 0.8000\n",
      "Epoch 325/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4222 - accuracy: 0.7995\n",
      "Epoch 326/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4189 - accuracy: 0.8018\n",
      "Epoch 327/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4215 - accuracy: 0.8020\n",
      "Epoch 328/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4227 - accuracy: 0.7965\n",
      "Epoch 329/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4236 - accuracy: 0.7977\n",
      "Epoch 330/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4244 - accuracy: 0.7996\n",
      "Epoch 331/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4211 - accuracy: 0.7984\n",
      "Epoch 332/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4182 - accuracy: 0.8011\n",
      "Epoch 333/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4247 - accuracy: 0.7988\n",
      "Epoch 334/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4226 - accuracy: 0.8000\n",
      "Epoch 335/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4220 - accuracy: 0.7979\n",
      "Epoch 336/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4195 - accuracy: 0.7995\n",
      "Epoch 337/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4262 - accuracy: 0.7965\n",
      "Epoch 338/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4185 - accuracy: 0.8014\n",
      "Epoch 339/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4204 - accuracy: 0.8035\n",
      "Epoch 340/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4263 - accuracy: 0.7972\n",
      "Epoch 341/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4201 - accuracy: 0.7989\n",
      "Epoch 342/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4189 - accuracy: 0.7982\n",
      "Epoch 343/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4206 - accuracy: 0.8025\n",
      "Epoch 344/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4245 - accuracy: 0.7986\n",
      "Epoch 345/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4201 - accuracy: 0.7995\n",
      "Epoch 346/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4233 - accuracy: 0.8021\n",
      "Epoch 347/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4179 - accuracy: 0.8039\n",
      "Epoch 348/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4209 - accuracy: 0.7998\n",
      "Epoch 349/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4168 - accuracy: 0.8014\n",
      "Epoch 350/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4210 - accuracy: 0.8007\n",
      "Epoch 351/500\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 0.4203 - accuracy: 0.7986\n",
      "Epoch 352/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4196 - accuracy: 0.7991\n",
      "Epoch 353/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4209 - accuracy: 0.8002\n",
      "Epoch 354/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4586 - accuracy: 0.7894\n",
      "Epoch 355/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4278 - accuracy: 0.7966\n",
      "Epoch 356/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4238 - accuracy: 0.7949\n",
      "Epoch 357/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4306 - accuracy: 0.7933\n",
      "Epoch 358/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4263 - accuracy: 0.7961\n",
      "Epoch 359/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4206 - accuracy: 0.8009\n",
      "Epoch 360/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4228 - accuracy: 0.7984\n",
      "Epoch 361/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4186 - accuracy: 0.7993\n",
      "Epoch 362/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4207 - accuracy: 0.8018\n",
      "Epoch 363/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4188 - accuracy: 0.8023\n",
      "Epoch 364/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4244 - accuracy: 0.8014\n",
      "Epoch 365/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4219 - accuracy: 0.7986\n",
      "Epoch 366/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4222 - accuracy: 0.8023\n",
      "Epoch 367/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4179 - accuracy: 0.7996\n",
      "Epoch 368/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4179 - accuracy: 0.7998\n",
      "Epoch 369/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4186 - accuracy: 0.8016\n",
      "Epoch 370/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4401 - accuracy: 0.7941\n",
      "Epoch 371/500\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 0.4196 - accuracy: 0.8000\n",
      "Epoch 372/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4180 - accuracy: 0.8027\n",
      "Epoch 373/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4213 - accuracy: 0.7986\n",
      "Epoch 374/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4176 - accuracy: 0.8032\n",
      "Epoch 375/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4222 - accuracy: 0.7970\n",
      "Epoch 376/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4171 - accuracy: 0.8050\n",
      "Epoch 377/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4284 - accuracy: 0.8005\n",
      "Epoch 378/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4190 - accuracy: 0.8020\n",
      "Epoch 379/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4177 - accuracy: 0.8014\n",
      "Epoch 380/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4189 - accuracy: 0.8023\n",
      "Epoch 381/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4198 - accuracy: 0.7996\n",
      "Epoch 382/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4178 - accuracy: 0.8021\n",
      "Epoch 383/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4196 - accuracy: 0.8012\n",
      "Epoch 384/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4171 - accuracy: 0.8007\n",
      "Epoch 385/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4156 - accuracy: 0.8035\n",
      "Epoch 386/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4217 - accuracy: 0.8004\n",
      "Epoch 387/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4171 - accuracy: 0.8032\n",
      "Epoch 388/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4226 - accuracy: 0.7989\n",
      "Epoch 389/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4202 - accuracy: 0.7988\n",
      "Epoch 390/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4195 - accuracy: 0.7966\n",
      "Epoch 391/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4186 - accuracy: 0.8027\n",
      "Epoch 392/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4214 - accuracy: 0.7984\n",
      "Epoch 393/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4167 - accuracy: 0.8000\n",
      "Epoch 394/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4214 - accuracy: 0.7968\n",
      "Epoch 395/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4290 - accuracy: 0.7927\n",
      "Epoch 396/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4190 - accuracy: 0.7984\n",
      "Epoch 397/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4179 - accuracy: 0.8021\n",
      "Epoch 398/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4210 - accuracy: 0.7977\n",
      "Epoch 399/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4201 - accuracy: 0.8002\n",
      "Epoch 400/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4225 - accuracy: 0.8005\n",
      "Epoch 401/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4200 - accuracy: 0.8018\n",
      "Epoch 402/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4170 - accuracy: 0.8025\n",
      "Epoch 403/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4186 - accuracy: 0.7991\n",
      "Epoch 404/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4173 - accuracy: 0.8050\n",
      "Epoch 405/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4205 - accuracy: 0.7986\n",
      "Epoch 406/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4169 - accuracy: 0.8012\n",
      "Epoch 407/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4203 - accuracy: 0.8023\n",
      "Epoch 408/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4173 - accuracy: 0.8005\n",
      "Epoch 409/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4214 - accuracy: 0.7998\n",
      "Epoch 410/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4188 - accuracy: 0.7995\n",
      "Epoch 411/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4196 - accuracy: 0.8018\n",
      "Epoch 412/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4212 - accuracy: 0.7984\n",
      "Epoch 413/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4180 - accuracy: 0.8007\n",
      "Epoch 414/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4172 - accuracy: 0.8023\n",
      "Epoch 415/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4187 - accuracy: 0.8046\n",
      "Epoch 416/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4176 - accuracy: 0.8018\n",
      "Epoch 417/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4253 - accuracy: 0.7954\n",
      "Epoch 418/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4245 - accuracy: 0.8000\n",
      "Epoch 419/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4290 - accuracy: 0.7975\n",
      "Epoch 420/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4197 - accuracy: 0.7973\n",
      "Epoch 421/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4559 - accuracy: 0.7892\n",
      "Epoch 422/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4268 - accuracy: 0.7993\n",
      "Epoch 423/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4224 - accuracy: 0.8030\n",
      "Epoch 424/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4208 - accuracy: 0.7996\n",
      "Epoch 425/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4225 - accuracy: 0.8007\n",
      "Epoch 426/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4209 - accuracy: 0.8025\n",
      "Epoch 427/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4205 - accuracy: 0.8000\n",
      "Epoch 428/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4190 - accuracy: 0.7998\n",
      "Epoch 429/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4173 - accuracy: 0.8035\n",
      "Epoch 430/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4182 - accuracy: 0.7996\n",
      "Epoch 431/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4388 - accuracy: 0.7959\n",
      "Epoch 432/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4203 - accuracy: 0.7984\n",
      "Epoch 433/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4191 - accuracy: 0.8035\n",
      "Epoch 434/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4189 - accuracy: 0.7970\n",
      "Epoch 435/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4191 - accuracy: 0.8009\n",
      "Epoch 436/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4191 - accuracy: 0.8021\n",
      "Epoch 437/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4182 - accuracy: 0.8014\n",
      "Epoch 438/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4234 - accuracy: 0.7947\n",
      "Epoch 439/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4188 - accuracy: 0.8023\n",
      "Epoch 440/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4175 - accuracy: 0.8076\n",
      "Epoch 441/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4190 - accuracy: 0.8030\n",
      "Epoch 442/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4192 - accuracy: 0.8018\n",
      "Epoch 443/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4165 - accuracy: 0.8030\n",
      "Epoch 444/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4220 - accuracy: 0.8009\n",
      "Epoch 445/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4184 - accuracy: 0.8032\n",
      "Epoch 446/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4186 - accuracy: 0.8004\n",
      "Epoch 447/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4157 - accuracy: 0.7989\n",
      "Epoch 448/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4195 - accuracy: 0.7996\n",
      "Epoch 449/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4155 - accuracy: 0.8032\n",
      "Epoch 450/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4189 - accuracy: 0.7998\n",
      "Epoch 451/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4189 - accuracy: 0.7982\n",
      "Epoch 452/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4217 - accuracy: 0.7989\n",
      "Epoch 453/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4270 - accuracy: 0.7924\n",
      "Epoch 454/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4181 - accuracy: 0.8027\n",
      "Epoch 455/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4168 - accuracy: 0.8028\n",
      "Epoch 456/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4245 - accuracy: 0.7973\n",
      "Epoch 457/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4206 - accuracy: 0.7998\n",
      "Epoch 458/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4183 - accuracy: 0.8039\n",
      "Epoch 459/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4277 - accuracy: 0.7968\n",
      "Epoch 460/500\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 0.4166 - accuracy: 0.7991\n",
      "Epoch 461/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4159 - accuracy: 0.8030\n",
      "Epoch 462/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4178 - accuracy: 0.8032\n",
      "Epoch 463/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4157 - accuracy: 0.8044\n",
      "Epoch 464/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4184 - accuracy: 0.8014\n",
      "Epoch 465/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4146 - accuracy: 0.8037\n",
      "Epoch 466/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4244 - accuracy: 0.8004\n",
      "Epoch 467/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4161 - accuracy: 0.8023\n",
      "Epoch 468/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4172 - accuracy: 0.8025\n",
      "Epoch 469/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4195 - accuracy: 0.8005\n",
      "Epoch 470/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4308 - accuracy: 0.7929\n",
      "Epoch 471/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4226 - accuracy: 0.7947\n",
      "Epoch 472/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4192 - accuracy: 0.7984\n",
      "Epoch 473/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4143 - accuracy: 0.8048\n",
      "Epoch 474/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4203 - accuracy: 0.8000\n",
      "Epoch 475/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4177 - accuracy: 0.8021\n",
      "Epoch 476/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4167 - accuracy: 0.8021\n",
      "Epoch 477/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4178 - accuracy: 0.8060\n",
      "Epoch 478/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4158 - accuracy: 0.8041\n",
      "Epoch 479/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4162 - accuracy: 0.8051\n",
      "Epoch 480/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4162 - accuracy: 0.8037\n",
      "Epoch 481/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4158 - accuracy: 0.7977\n",
      "Epoch 482/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4222 - accuracy: 0.7950\n",
      "Epoch 483/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4143 - accuracy: 0.8051\n",
      "Epoch 484/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4153 - accuracy: 0.8046\n",
      "Epoch 485/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4168 - accuracy: 0.8025\n",
      "Epoch 486/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4167 - accuracy: 0.8035\n",
      "Epoch 487/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4176 - accuracy: 0.7961\n",
      "Epoch 488/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4160 - accuracy: 0.8032\n",
      "Epoch 489/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4157 - accuracy: 0.8023\n",
      "Epoch 490/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4159 - accuracy: 0.8050\n",
      "Epoch 491/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4249 - accuracy: 0.7989\n",
      "Epoch 492/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4163 - accuracy: 0.8034\n",
      "Epoch 493/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4177 - accuracy: 0.8028\n",
      "Epoch 494/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4174 - accuracy: 0.7991\n",
      "Epoch 495/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.4171 - accuracy: 0.8009\n",
      "Epoch 496/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4173 - accuracy: 0.7991\n",
      "Epoch 497/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4156 - accuracy: 0.8025\n",
      "Epoch 498/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4169 - accuracy: 0.8005\n",
      "Epoch 499/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4156 - accuracy: 0.8027\n",
      "Epoch 500/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4166 - accuracy: 0.8004\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1ce90bebb48>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=500, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52c88157-0121-4152-a3fc-acab3c4b5639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "y_hat = model.predict(X_test)\n",
    "y_hat= [0 if val < 0.5 else 1 for val in y_hat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ab5eaa5-fd50-4cae-8702-c040e30a8ea0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 1,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 1,\n 1,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 0,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 0,\n 1,\n 0,\n 1,\n 1,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 1,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 1,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 1,\n 1,\n 0,\n 1,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 1,\n 1,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 1,\n 1,\n 0,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 0,\n 0,\n 1,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 1,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 0,\n 0,\n 1,\n 0,\n 1,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 0,\n 1,\n ...]"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5018454d-2a8d-4b31-b56c-5571e14df759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.8140525195173882"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d39651c-e5e8-44b5-94a7-64fe46224ca1",
   "metadata": {},
   "source": [
    "## Saving a model and Reloding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6ebd4db-688f-45f0-8597-8d49c000794e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Churn_tfmodel2\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"Churn_tfmodel2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4ab3182c-0c7c-48b8-8e3e-4cefa912b5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4f8facfd-a3c7-4bf7-9781-d1ae8112652d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('Churn_tfmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a0a22e-0627-4e04-8cc9-adaebadd3fd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "portfolio",
   "language": "python",
   "name": "portfolio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}